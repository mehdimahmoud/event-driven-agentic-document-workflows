{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cde6753-c327-4c1d-9ea8-63a1f851ddff",
   "metadata": {},
   "source": [
    "# Lesson 6: Use your voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121aec5-1316-4186-aad5-914aecb6c6cf",
   "metadata": {},
   "source": [
    "**Lesson objective**: Get voice feedback \n",
    "\n",
    "So far we've set up a moderately complex workflow with a human feedback loop. Let's run it through the visualizer to see what it looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9456a5ef",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to run the notebook cell by cell. Please try to avoid running all cells at once.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497254a3-476d-401f-9d40-76e9a364756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "180fcb51-4d47-4877-a5b3-f773c64f1f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "from llama_parse import LlamaParse\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    "    InputRequiredEvent,\n",
    "    HumanResponseEvent\n",
    ")\n",
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "from llama_index.readers.whisper import WhisperReader\n",
    "import gradio as gr\n",
    "import asyncio\n",
    "from queue import Queue\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from helper import get_openai_api_key, get_llama_cloud_api_key\n",
    "\n",
    "llama_cloud_api_key = get_llama_cloud_api_key()\n",
    "openai_api_key = get_openai_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc3a2f78-d56f-4bbb-9664-3da5f90cf102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParseFormEvent(Event):\n",
    "    application_form: str\n",
    "\n",
    "class QueryEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class ResponseEvent(Event):\n",
    "    response: str\n",
    "\n",
    "class FeedbackEvent(Event):\n",
    "    feedback: str\n",
    "\n",
    "class GenerateQuestionsEvent(Event):\n",
    "    pass\n",
    "\n",
    "class RAGWorkflow(Workflow):\n",
    "    storage_dir = \"./storage\"\n",
    "    llm: OpenAI\n",
    "    query_engine: VectorStoreIndex\n",
    "\n",
    "    @step\n",
    "    async def set_up(self, ctx: Context, ev: StartEvent) -> ParseFormEvent:\n",
    "\n",
    "        if not ev.resume_file:\n",
    "            raise ValueError(\"No resume file provided\")\n",
    "\n",
    "        if not ev.application_form:\n",
    "            raise ValueError(\"No application form provided\")\n",
    "\n",
    "        # give ourselves an LLM to work with\n",
    "        self.llm = OpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "        # ingest our data and set up the query engine\n",
    "        if os.path.exists(self.storage_dir):\n",
    "            # we've already ingested our documents\n",
    "            storage_context = StorageContext.from_defaults(persist_dir=self.storage_dir)\n",
    "            index = load_index_from_storage(storage_context)\n",
    "        else:\n",
    "            # we need to parse and load our documents\n",
    "            documents = LlamaParse(\n",
    "                api_key=llama_cloud_api_key,\n",
    "                result_type=\"markdown\",\n",
    "                content_guideline_instruction=\"This is a resume, gather related facts together and format it as bullet points with headers\"\n",
    "            ).load_data(ev.resume_file)\n",
    "            # embed and index the documents\n",
    "            index = VectorStoreIndex.from_documents(\n",
    "                documents,\n",
    "                embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\")\n",
    "            )\n",
    "            index.storage_context.persist(persist_dir=self.storage_dir)\n",
    "\n",
    "        # either way, create a query engine\n",
    "        self.query_engine = index.as_query_engine(llm=self.llm, similarity_top_k=5)\n",
    "\n",
    "        # let's pass our application form to a new step where we parse it\n",
    "        return ParseFormEvent(application_form=ev.application_form)\n",
    "\n",
    "    # we've separated the form parsing from the question generation\n",
    "    @step\n",
    "    async def parse_form(self, ctx: Context, ev: ParseFormEvent) -> GenerateQuestionsEvent:\n",
    "        parser = LlamaParse(\n",
    "            api_key=llama_cloud_api_key,\n",
    "            result_type=\"markdown\",\n",
    "            content_guideline_instruction=\"This is a job application form. Create a list of all the fields that need to be filled in.\",\n",
    "            formatting_instruction=\"Return a bulleted list of the fields ONLY.\"\n",
    "        )\n",
    "\n",
    "        # get the LLM to convert the parsed form into JSON\n",
    "        result = parser.load_data(ev.application_form)[0]\n",
    "        raw_json = self.llm.complete(\n",
    "            f\"This is a parsed form. Convert it into a JSON object containing only the list of fields to be filled in, in the form {{ fields: [...] }}. <form>{result.text}</form>. Return JSON ONLY, no markdown.\")\n",
    "        fields = json.loads(raw_json.text)[\"fields\"]\n",
    "\n",
    "        await ctx.set(\"fields_to_fill\", fields)\n",
    "\n",
    "        return GenerateQuestionsEvent()\n",
    "\n",
    "    # this step can get triggered either by GenerateQuestionsEvent or a FeedbackEvent\n",
    "    @step\n",
    "    async def generate_questions(self, ctx: Context, ev: GenerateQuestionsEvent | FeedbackEvent) -> QueryEvent:\n",
    "\n",
    "        # get the list of fields to fill in\n",
    "        fields = await ctx.get(\"fields_to_fill\")\n",
    "\n",
    "        # generate one query for each of the fields, and fire them off\n",
    "        for field in fields:\n",
    "            question = f\"How would you answer this question about the candidate? <field>{field}</field>\"\n",
    "\n",
    "            if hasattr(ev,\"feedback\"):\n",
    "                question += f\"\"\"\n",
    "                    \\nWe previously got feedback about how we answered the questions.\n",
    "                    It might not be relevant to this particular field, but here it is:\n",
    "                    <feedback>{ev.feedback}</feedback>\n",
    "                \"\"\"\n",
    "\n",
    "            ctx.send_event(QueryEvent(\n",
    "                field=field,\n",
    "                query=question\n",
    "            ))\n",
    "\n",
    "        # store the number of fields so we know how many to wait for later\n",
    "        await ctx.set(\"total_fields\", len(fields))\n",
    "        return\n",
    "\n",
    "    @step\n",
    "    async def ask_question(self, ctx: Context, ev: QueryEvent) -> ResponseEvent:\n",
    "        print(f\"Asking question: {ev.query}\")\n",
    "\n",
    "        response = self.query_engine.query(f\"This is a question about the specific resume we have in our database: {ev.query}\")\n",
    "\n",
    "        print(f\"Answer was: {str(response)}\")\n",
    "\n",
    "        return ResponseEvent(field=ev.field, response=response.response)\n",
    "\n",
    "    # we now emit an InputRequiredEvent\n",
    "    @step\n",
    "    async def fill_in_application(self, ctx: Context, ev: ResponseEvent) -> InputRequiredEvent:\n",
    "        # get the total number of fields to wait for\n",
    "        total_fields = await ctx.get(\"total_fields\")\n",
    "\n",
    "        responses = ctx.collect_events(ev, [ResponseEvent] * total_fields)\n",
    "        if responses is None:\n",
    "            return None # do nothing if there's nothing to do yet\n",
    "\n",
    "        # we've got all the responses!\n",
    "        responseList = \"\\n\".join(\"Field: \" + r.field + \"\\n\" + \"Response: \" + r.response for r in responses)\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You are given a list of fields in an application form and responses to\n",
    "            questions about those fields from a resume. Combine the two into a list of\n",
    "            fields and succinct, factual answers to fill in those fields.\n",
    "\n",
    "            <responses>\n",
    "            {responseList}\n",
    "            </responses>\n",
    "        \"\"\")\n",
    "\n",
    "        # save the result for later\n",
    "        await ctx.set(\"filled_form\", str(result))\n",
    "\n",
    "        # Let's get a human in the loop\n",
    "        return InputRequiredEvent(\n",
    "            prefix=\"How does this look? Give me any feedback you have on any of the answers.\",\n",
    "            result=result\n",
    "        )\n",
    "\n",
    "    # Accept the feedback.\n",
    "    @step\n",
    "    async def get_feedback(self, ctx: Context, ev: HumanResponseEvent) -> FeedbackEvent | StopEvent:\n",
    "\n",
    "        result = self.llm.complete(f\"\"\"\n",
    "            You have received some human feedback on the form-filling task you've done.\n",
    "            Does everything look good, or is there more work to be done?\n",
    "            <feedback>\n",
    "            {ev.response}\n",
    "            </feedback>\n",
    "            If everything is fine, respond with just the word 'OKAY'.\n",
    "            If there's any other feedback, respond with just the word 'FEEDBACK'.\n",
    "        \"\"\")\n",
    "\n",
    "        verdict = result.text.strip()\n",
    "\n",
    "        print(f\"LLM says the verdict was {verdict}\")\n",
    "        if (verdict == \"OKAY\"):\n",
    "            return StopEvent(result=await ctx.get(\"filled_form\"))\n",
    "        else:\n",
    "            return FeedbackEvent(feedback=ev.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0039610-c02e-4e7e-9c9f-1dc56450543d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workflows/lesson_6.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[103181:103289:0813/161018.816527:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.DBus.Properties.Get: object_path= /org/freedesktop/UPower: org.freedesktop.DBus.Error.ServiceUnknown: The name org.freedesktop.UPower was not provided by any .service files\n",
      "[103181:103289:0813/161018.816879:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.UPower.GetDisplayDevice: object_path= /org/freedesktop/UPower: org.freedesktop.DBus.Error.ServiceUnknown: The name org.freedesktop.UPower was not provided by any .service files\n",
      "[103181:103289:0813/161018.817388:ERROR:dbus/object_proxy.cc:590] Failed to call method: org.freedesktop.UPower.EnumerateDevices: object_path= /org/freedesktop/UPower: org.freedesktop.DBus.Error.ServiceUnknown: The name org.freedesktop.UPower was not provided by any .service files\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755097822.975442  103207 voice_transcription.cc:58] Registering VoiceTranscriptionCapability\n",
      "Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors (tensor#-1 is a dynamic-sized tensor).\n"
     ]
    }
   ],
   "source": [
    "WORKFLOW_FILE = \"workflows/lesson_6.html\"\n",
    "draw_all_possible_flows(RAGWorkflow, filename=WORKFLOW_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "777454c5-31d0-4b23-ac03-f74207fbaf83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       " <div style=\"width: 100%; height: 800px; overflow: hidden;\"> <html>\n",
       "    <head>\n",
       "        <meta charset=\"utf-8\">\n",
       "        \n",
       "            <script src=\"lib/bindings/utils.js\"></script>\n",
       "            <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css\" integrity=\"sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js\" integrity=\"sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\"></script>\n",
       "            \n",
       "        \n",
       "<center>\n",
       "<h1></h1>\n",
       "</center>\n",
       "\n",
       "<!-- <link rel=\"stylesheet\" href=\"../node_modules/vis/dist/vis.min.css\" type=\"text/css\" />\n",
       "<script type=\"text/javascript\" src=\"../node_modules/vis/dist/vis.js\"> </script>-->\n",
       "        <link\n",
       "          href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css\"\n",
       "          rel=\"stylesheet\"\n",
       "          integrity=\"sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        />\n",
       "        <script\n",
       "          src=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js\"\n",
       "          integrity=\"sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf\"\n",
       "          crossorigin=\"anonymous\"\n",
       "        ></script>\n",
       "\n",
       "\n",
       "        <center>\n",
       "          <h1></h1>\n",
       "        </center>\n",
       "        <style type=\"text/css\">\n",
       "\n",
       "             #mynetwork {\n",
       "                 width: 100%;\n",
       "                 height: 750px;\n",
       "                 background-color: #ffffff;\n",
       "                 border: 1px solid lightgray;\n",
       "                 position: relative;\n",
       "                 float: left;\n",
       "             }\n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "\n",
       "             \n",
       "        </style>\n",
       "    </head>\n",
       "\n",
       "\n",
       "    <body>\n",
       "        <div class=\"card\" style=\"width: 100%\">\n",
       "            \n",
       "            \n",
       "            <div id=\"mynetwork\" class=\"card-body\"></div>\n",
       "        </div>\n",
       "\n",
       "        \n",
       "        \n",
       "\n",
       "        <script type=\"text/javascript\">\n",
       "\n",
       "              // initialize global variables.\n",
       "              var edges;\n",
       "              var nodes;\n",
       "              var allNodes;\n",
       "              var allEdges;\n",
       "              var nodeColors;\n",
       "              var originalNodes;\n",
       "              var network;\n",
       "              var container;\n",
       "              var options, data;\n",
       "              var filter = {\n",
       "                  item : '',\n",
       "                  property : '',\n",
       "                  value : []\n",
       "              };\n",
       "\n",
       "              \n",
       "\n",
       "              \n",
       "\n",
       "              // This method is responsible for drawing the graph, returns the drawn network\n",
       "              function drawGraph() {\n",
       "                  var container = document.getElementById('mynetwork');\n",
       "\n",
       "                  \n",
       "\n",
       "                  // parsing and collecting nodes and edges from the python\n",
       "                  nodes = new vis.DataSet([{\"color\": \"#ADD8E6\", \"id\": \"_done\", \"label\": \"_done\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#FFA07A\", \"id\": \"StopEvent\", \"label\": \"StopEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"ask_question\", \"label\": \"ask_question\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"QueryEvent\", \"label\": \"QueryEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ResponseEvent\", \"label\": \"ResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"fill_in_application\", \"label\": \"fill_in_application\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"InputRequiredEvent\", \"label\": \"InputRequiredEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#BEDAE4\", \"id\": \"external_step\", \"label\": \"external_step\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"generate_questions\", \"label\": \"generate_questions\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"GenerateQuestionsEvent\", \"label\": \"GenerateQuestionsEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"FeedbackEvent\", \"label\": \"FeedbackEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"get_feedback\", \"label\": \"get_feedback\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"HumanResponseEvent\", \"label\": \"HumanResponseEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"parse_form\", \"label\": \"parse_form\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#90EE90\", \"id\": \"ParseFormEvent\", \"label\": \"ParseFormEvent\", \"shape\": \"ellipse\", \"title\": null}, {\"color\": \"#ADD8E6\", \"id\": \"set_up\", \"label\": \"set_up\", \"shape\": \"box\", \"title\": null}, {\"color\": \"#E27AFF\", \"id\": \"StartEvent\", \"label\": \"StartEvent\", \"shape\": \"ellipse\", \"title\": null}]);\n",
       "                  edges = new vis.DataSet([{\"arrows\": \"to\", \"from\": \"StopEvent\", \"to\": \"_done\"}, {\"arrows\": \"to\", \"from\": \"ask_question\", \"to\": \"ResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"QueryEvent\", \"to\": \"ask_question\"}, {\"arrows\": \"to\", \"from\": \"fill_in_application\", \"to\": \"InputRequiredEvent\"}, {\"arrows\": \"to\", \"from\": \"InputRequiredEvent\", \"to\": \"external_step\"}, {\"arrows\": \"to\", \"from\": \"ResponseEvent\", \"to\": \"fill_in_application\"}, {\"arrows\": \"to\", \"from\": \"generate_questions\", \"to\": \"QueryEvent\"}, {\"arrows\": \"to\", \"from\": \"GenerateQuestionsEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"FeedbackEvent\", \"to\": \"generate_questions\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"FeedbackEvent\"}, {\"arrows\": \"to\", \"from\": \"get_feedback\", \"to\": \"StopEvent\"}, {\"arrows\": \"to\", \"from\": \"HumanResponseEvent\", \"to\": \"get_feedback\"}, {\"arrows\": \"to\", \"from\": \"external_step\", \"to\": \"HumanResponseEvent\"}, {\"arrows\": \"to\", \"from\": \"parse_form\", \"to\": \"GenerateQuestionsEvent\"}, {\"arrows\": \"to\", \"from\": \"ParseFormEvent\", \"to\": \"parse_form\"}, {\"arrows\": \"to\", \"from\": \"set_up\", \"to\": \"ParseFormEvent\"}, {\"arrows\": \"to\", \"from\": \"StartEvent\", \"to\": \"set_up\"}]);\n",
       "\n",
       "                  nodeColors = {};\n",
       "                  allNodes = nodes.get({ returnType: \"Object\" });\n",
       "                  for (nodeId in allNodes) {\n",
       "                    nodeColors[nodeId] = allNodes[nodeId].color;\n",
       "                  }\n",
       "                  allEdges = edges.get({ returnType: \"Object\" });\n",
       "                  // adding nodes and edges to the graph\n",
       "                  data = {nodes: nodes, edges: edges};\n",
       "\n",
       "                  var options = {\n",
       "    \"configure\": {\n",
       "        \"enabled\": false\n",
       "    },\n",
       "    \"edges\": {\n",
       "        \"color\": {\n",
       "            \"inherit\": true\n",
       "        },\n",
       "        \"smooth\": {\n",
       "            \"enabled\": true,\n",
       "            \"type\": \"dynamic\"\n",
       "        }\n",
       "    },\n",
       "    \"interaction\": {\n",
       "        \"dragNodes\": true,\n",
       "        \"hideEdgesOnDrag\": false,\n",
       "        \"hideNodesOnDrag\": false\n",
       "    },\n",
       "    \"physics\": {\n",
       "        \"enabled\": true,\n",
       "        \"stabilization\": {\n",
       "            \"enabled\": true,\n",
       "            \"fit\": true,\n",
       "            \"iterations\": 1000,\n",
       "            \"onlyDynamicEdges\": false,\n",
       "            \"updateInterval\": 50\n",
       "        }\n",
       "    }\n",
       "};\n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  network = new vis.Network(container, data, options);\n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "                  \n",
       "\n",
       "\n",
       "                  \n",
       "\n",
       "                  return network;\n",
       "\n",
       "              }\n",
       "              drawGraph();\n",
       "        </script>\n",
       "    </body>\n",
       "</html> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "isolated": true
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML, DisplayHandle\n",
    "from helper import extract_html_content\n",
    "\n",
    "html_content = extract_html_content(WORKFLOW_FILE)\n",
    "display(HTML(html_content), metadata=dict(isolated=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d55ed9-88d0-44ac-b4a3-eb605bcb0638",
   "metadata": {},
   "source": [
    "Cool! You can see the path all the way to the end and the feedback loop is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1147987",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> 💻 &nbsp; <b>To access <code>fake_application_form.pdf</code>, <code>fake_resume.pdf</code>, <code>requirements.txt</code> and <code>helper.py</code> files:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. The form and resume are inside the data folder.\n",
    "\n",
    "<p> ⬇ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "<p> 📒 &nbsp; For more help, please see the <em>\"Appendix – Tips and Help\"</em> Lesson.</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a258f",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> 🚨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c82425-bdda-4f93-9226-fc4e4834d8ef",
   "metadata": {},
   "source": [
    "## Getting voice feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fad645-47db-436b-84e2-914acc89dee3",
   "metadata": {},
   "source": [
    "Now, just for fun, you'll do one more thing: change the feedback from text feedback to actual words spoken out loud. To do this we'll use a different model from OpenAI called Whisper. LlamaIndex has a built-in way to transcribe audio files into text using Whisper.\n",
    "\n",
    "Here's a function that takes a file and uses Whisper to return just the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53149fea-7383-4c39-a58c-5836857f69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_speech(filepath):\n",
    "    if filepath is None:\n",
    "        gr.Warning(\"No audio found, please retry.\")\n",
    "    audio_file= open(filepath, \"rb\")\n",
    "    reader = WhisperReader(\n",
    "        model=\"whisper-1\",\n",
    "        api_key=openai_api_key,\n",
    "    )\n",
    "    documents = reader.load_data(filepath)\n",
    "    return documents[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67c70a-48a6-4fcd-bf18-2c390cce5855",
   "metadata": {},
   "source": [
    "But before we can use it, you need to capture some audio from your microphone. That involves some extra steps!\n",
    "\n",
    "First, create a callback function that saves data to a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53efc82-cbd2-448d-bc6f-96d6bc1486f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_transcription(output):\n",
    "    global transcription_value\n",
    "    transcription_value = output\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389e3292-2d56-450c-bcb1-65b510a994ee",
   "metadata": {},
   "source": [
    "Now use Gradio, which has special widgets that can render inside a notebook, to create an interface for capturing audio from a microphone. When the audio is captured, it calls `transcribe_speech` on the recorded data, and calls `store_transcription` on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e38ac6-1e88-46dd-ace4-77241aff9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mic_transcribe = gr.Interface(\n",
    "    fn=lambda x: store_transcription(transcribe_speech(x)),\n",
    "    inputs=gr.Audio(sources=\"microphone\",\n",
    "                    type=\"filepath\"),\n",
    "    outputs=gr.Textbox(label=\"Transcription\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e04512-d9ab-450d-850f-072ae67bc451",
   "metadata": {},
   "source": [
    "In Gradio, you further define a visual interface containing this microphone input and output, and then launch it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189076f4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to wait for the gradio interface to load. A popup window will appear and ask you to allow the use of your microphone. To record audio, make sure to click on record -> stop -> submit. Make sure the audio is captured before clicking on 'submit'.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc89e72-76e0-4cfd-904b-0d3dd058532b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing dataset file at: .gradio/flagged/dataset1.csv\n"
     ]
    }
   ],
   "source": [
    "test_interface = gr.Blocks()\n",
    "with test_interface:\n",
    "    gr.TabbedInterface(\n",
    "        [mic_transcribe],\n",
    "        [\"Transcribe Microphone\"]\n",
    "    )\n",
    "\n",
    "test_interface.launch(\n",
    "    share=False, \n",
    "    server_port=8000, \n",
    "    prevent_thread_lock=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30d95b-47bb-45db-9d42-5835120d92ae",
   "metadata": {},
   "source": [
    "You can now print out the transcription, which is stored in that global variable you created earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5de79c4-dbda-4103-baa1-5b315af6c1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you hear me, computer?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transcription_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ee4ba-f744-4b7c-906f-b26151700d27",
   "metadata": {},
   "source": [
    "You're going to want to run Gradio again, so it's a good idea to shut down the Gradio interface you were using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "436f51ba-760d-4af6-8da1-8088e7c8ebcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8000\n"
     ]
    }
   ],
   "source": [
    "test_interface.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce0f309",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff1d7; padding:15px;\"> <b> Note</b>: Make sure to run the previous cell to close the Gradio interface before running the next cell.</div>                                                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b05ec0-495f-4376-a167-43efc1db04cd",
   "metadata": {},
   "source": [
    "Now you're going to create an entirely new class, a Transcription Handler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f30a2e-2c39-411a-917c-b78549e5eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New! Transcription handler.\n",
    "class TranscriptionHandler:\n",
    "\n",
    "    # we create a queue to hold transcription values\n",
    "    def __init__(self):\n",
    "        self.transcription_queue = Queue()\n",
    "        self.interface = None\n",
    "\n",
    "    # every time we record something we put it in the queue\n",
    "    def store_transcription(self, output):\n",
    "        self.transcription_queue.put(output)\n",
    "        return output\n",
    "\n",
    "    # This is the same interface and transcription logic as before\n",
    "    # except it stores the result in a queue instead of a global\n",
    "    def create_interface(self):\n",
    "        mic_transcribe = gr.Interface(\n",
    "            fn=lambda x: self.store_transcription(transcribe_speech(x)),\n",
    "            inputs=gr.Audio(sources=\"microphone\", type=\"filepath\"),\n",
    "            outputs=gr.Textbox(label=\"Transcription\")\n",
    "        )\n",
    "        self.interface = gr.Blocks()\n",
    "        with self.interface:\n",
    "            gr.TabbedInterface(\n",
    "                [mic_transcribe],\n",
    "                [\"Transcribe Microphone\"]\n",
    "            )\n",
    "        return self.interface\n",
    "\n",
    "    # we launch the transcription interface\n",
    "    async def get_transcription(self):\n",
    "        self.interface = self.create_interface()\n",
    "        self.interface.launch(\n",
    "            share=False,\n",
    "            server_port=8000, \n",
    "            prevent_thread_lock=True\n",
    "        )\n",
    "\n",
    "        # we poll every 1.5 seconds waiting for something to end up in the queue\n",
    "        while True:\n",
    "            if not self.transcription_queue.empty():\n",
    "                result = self.transcription_queue.get()\n",
    "                if self.interface is not None:\n",
    "                    self.interface.close()\n",
    "                return result\n",
    "            await asyncio.sleep(1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e0042-5feb-4c25-8668-33debef828a7",
   "metadata": {},
   "source": [
    "Now you have a transcription handler, you can use it instead of the keyboard input interface when you're getting human input when you run your workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "905709d6-ad52-4514-a75e-2bae2cfbb802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from ./storage/index_store.json.\n",
      "WARNING: content_guideline_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "WARNING: formatting_instruction is deprecated and may be remove in a future release. Use system_prompt, system_prompt_append or user_prompt instead.\n",
      "Started parsing the file under job_id 4ecb752e-1343-4ce2-b874-1d0d516541d2\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "Answer was: Chen\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "Answer was: The candidate's phone number is not provided in the available information.\n",
      "Asking question: How would you answer this question about the candidate? <field>Linkedin</field>\n",
      "Answer was: The candidate's LinkedIn profile can be found at linkedin.com/in/sarahchen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "Answer was: The candidate has a project portfolio that includes notable projects such as EcoTrack, a full-stack application for tracking carbon footprint, which features a machine learning algorithm for personalized sustainability recommendations and was recognized in TechCrunch's \"Top 10 Environmental Impact Apps of 2023.\" Another project is ChatFlow, a real-time chat application that utilizes the WebSocket protocol and includes end-to-end encryption and message persistence, serving over 5000 monthly active users.\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "Answer was: Bachelor of Science in Computer Science\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "Answer was: The graduation date for the candidate is May 2017.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "Answer was: Senior Full Stack Developer\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "Answer was: TechFlow Solutions\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "Answer was: The candidate possesses a diverse set of technical skills across both frontend and backend development. On the frontend, they are proficient in React.js, Redux, Next.js, TypeScript, Vue.js, and Nuxt.js, along with HTML5, CSS3, and SASS/SCSS. They also have experience with testing frameworks like Jest and React Testing Library, as well as build tools such as WebPack and Babel. \n",
      "\n",
      "On the backend, their skills include Node.js, Express.js, Python, and Django, with expertise in GraphQL and REST APIs. They are familiar with databases like PostgreSQL and MongoDB. This combination of skills indicates a strong capability in full stack development, enabling them to handle various aspects of web application development effectively.\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "Answer was: The candidate is a strong fit for the position due to their extensive experience as a Full Stack Web Developer, with over 6 years in the field. They have a proven track record of successfully leading technical teams and implementing scalable web applications, particularly using technologies like React and Node.js, which are likely relevant to the role. Their experience in architecting a microservices-based e-commerce platform and optimizing API performance demonstrates their ability to handle high-traffic applications effectively.\n",
      "\n",
      "Additionally, the candidate's commitment to clean code and accessibility aligns with best practices in web development, ensuring that applications are not only functional but also user-friendly. Their certifications in cloud architecture further indicate a solid understanding of modern development environments, making them well-equipped to contribute to projects that require cloud solutions.\n",
      "\n",
      "Moreover, their passion for mentoring junior developers and involvement in open source contributions showcases their collaborative spirit and dedication to the tech community, which can enhance team dynamics and knowledge sharing within the organization. Overall, their technical skills, leadership experience, and commitment to quality make them an excellent candidate for the position.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "Answer was: Yes, the candidate has over 6 years of experience as a Full Stack Web Developer, with specific expertise in React.\n",
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 8000\n",
      "LLM says the verdict was FEEDBACK\n",
      "Asking question: How would you answer this question about the candidate? <field>First Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Sarah\n",
      "Asking question: How would you answer this question about the candidate? <field>Last Name</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Chen\n",
      "Asking question: How would you answer this question about the candidate? <field>Email</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: sarah.chen@email.com\n",
      "Asking question: How would you answer this question about the candidate? <field>Phone</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's resume does not provide a phone number.\n",
      "Asking question: How would you answer this question about the candidate? <field>Linkedin</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The LinkedIn profile for the candidate can be found at: linkedin.com/in/sarahchen.\n",
      "Asking question: How would you answer this question about the candidate? <field>Project Portfolio</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The Project Portfolio field for the candidate can be found at the following URL: [sarahchen.dev](http://sarahchen.dev).\n",
      "Asking question: How would you answer this question about the candidate? <field>Degree</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Bachelor of Science in Computer Science\n",
      "Asking question: How would you answer this question about the candidate? <field>Graduation Date</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The graduation date for the candidate is May 2017.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Job Title</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The current job title of the candidate is Senior Full Stack Developer.\n",
      "Asking question: How would you answer this question about the candidate? <field>Current Employer</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The current employer of the candidate is TechFlow Solutions, located in San Francisco, CA.\n",
      "Asking question: How would you answer this question about the candidate? <field>Technical Skills</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate's technical skills include:\n",
      "\n",
      "**Frontend:**\n",
      "- React.js, Redux, Next.js, TypeScript\n",
      "- Vue.js, Nuxt.js\n",
      "- HTML5, CSS3, SASS/SCSS\n",
      "- Jest, React Testing Library\n",
      "- WebPack, Babel\n",
      "\n",
      "**Backend:**\n",
      "- Node.js, Express.js\n",
      "- Python, Django\n",
      "- GraphQL, REST APIs\n",
      "- PostgreSQL, MongoDB\n",
      "Asking question: How would you answer this question about the candidate? <field>Describe why you’re a good fit for this position</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: The candidate is a strong fit for the position due to their extensive experience as a Full Stack Web Developer, with over 6 years in the field. They have successfully led technical teams and implemented significant improvements in deployment processes, showcasing their leadership and technical skills. Their expertise in React and Node.js aligns well with the requirements of the role, and their experience in architecting scalable applications demonstrates their ability to handle complex projects.\n",
      "\n",
      "Additionally, the candidate has a proven track record of enhancing application performance, as evidenced by their work on a microservices-based e-commerce platform and the implementation of a GraphQL API gateway. Their commitment to clean code and accessibility further highlights their dedication to quality and user experience.\n",
      "\n",
      "Moreover, their certifications in cloud architecture and development, along with their multilingual abilities, make them a versatile candidate who can contribute effectively in diverse environments. Overall, their combination of technical skills, leadership experience, and passion for mentoring junior developers positions them as an excellent candidate for the role.\n",
      "Asking question: How would you answer this question about the candidate? <field>Do you have 5 years of experience in React?</field>\n",
      "                    \n",
      "We previously got feedback about how we answered the questions.\n",
      "                    It might not be relevant to this particular field, but here it is:\n",
      "                    <feedback>The Project Portfolio field should be a URL.\n",
      "</feedback>\n",
      "                \n",
      "Answer was: Yes, the candidate has over 6 years of experience as a Full Stack Web Developer, which includes extensive work with React.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task was destroyed but it is pending!\n",
      "task: <Task pending name='Task-251' coro=<_delete_state() running at /home/mehdi/projects/event-driven-agentic-document-workflows/venv/lib/python3.12/site-packages/gradio/route_utils.py:980> wait_for=<Future pending cb=[Task.__wakeup()]>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:8000\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:8000/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, InputRequiredEvent):\n\u001b[32m     10\u001b[39m       \u001b[38;5;66;03m# Get transcription\u001b[39;00m\n\u001b[32m     11\u001b[39m       transcription_handler = TranscriptionHandler()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m       response = \u001b[38;5;28;01mawait\u001b[39;00m transcription_handler.get_transcription()\n\u001b[32m     14\u001b[39m       handler.ctx.send_event(\n\u001b[32m     15\u001b[39m           HumanResponseEvent(\n\u001b[32m     16\u001b[39m               response=response\n\u001b[32m     17\u001b[39m           )\n\u001b[32m     18\u001b[39m       )\n\u001b[32m     20\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m handler\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mTranscriptionHandler.get_transcription\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     44\u001b[39m         \u001b[38;5;28mself\u001b[39m.interface.close()\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m1.5\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/tasks.py:665\u001b[39m, in \u001b[36msleep\u001b[39m\u001b[34m(delay, result)\u001b[39m\n\u001b[32m    661\u001b[39m h = loop.call_later(delay,\n\u001b[32m    662\u001b[39m                     futures._set_result_unless_cancelled,\n\u001b[32m    663\u001b[39m                     future, result)\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m665\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    667\u001b[39m     h.cancel()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/asyncio/futures.py:287\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    288\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    289\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "w = RAGWorkflow(timeout=600, verbose=False)\n",
    "\n",
    "handler = w.run(\n",
    "    resume_file=\"./data/fake_resume.pdf\",\n",
    "    application_form=\"./data/fake_application_form.pdf\"\n",
    ")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "  if isinstance(event, InputRequiredEvent):\n",
    "      # Get transcription\n",
    "      transcription_handler = TranscriptionHandler()\n",
    "      response = await transcription_handler.get_transcription()\n",
    "\n",
    "      handler.ctx.send_event(\n",
    "          HumanResponseEvent(\n",
    "              response=response\n",
    "          )\n",
    "      )\n",
    "\n",
    "response = await handler\n",
    "print(\"Agent complete! Here's your final result:\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610fff23-cad0-4690-b166-2cc399f3e0c3",
   "metadata": {},
   "source": [
    "## Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb621327-73da-4946-a546-cd80732a03ae",
   "metadata": {},
   "source": [
    "You've successfully created an AI agent that responds to spoken feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562cecca",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98a735",
   "metadata": {},
   "source": [
    "To learn more about agentic document workflows, you check this [article](https://www.llamaindex.ai/blog/introducing-agentic-document-workflows) and theses [example implementations](https://github.com/run-llama/llamacloud-demo/tree/main/examples/document_workflows)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
